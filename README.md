# Chatbot with Qwen2 Model from Hugging Face

## Overview

This repository contains a simple implementation of a chatbot using the Qwen2-1.5B-Instruct model from Hugging Face. The code demonstrates how to load the model and tokenizer, generate responses to user prompts, and configure the chatbot for use on a CPU.

## Key Features

- **Model Loading**: The Qwen2-1.5B-Instruct model and its tokenizer are loaded from Hugging Face's model hub.
- **Text Generation**: The chatbot generates responses based on user input by applying a chat template and utilizing the deep learning model to produce coherent text outputs.
- **User-Friendly Interface**: The provided function allows easy integration of the chatbot into various applications by simply passing a user prompt to generate a response.

## Getting Started

### Prerequisites

Ensure you have the following installed:

- Python 3.x
- Hugging Face Transformers library (`transformers`)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/GabrielNM/Chatbot_free.git
   cd Chatbot_free

## Contributing
Contributions are welcome! Feel free to submit a Pull Request or open an Issue for any improvements or suggestions.

## License
This project is licensed under the MIT License. 

## Acknowledgments
This code leverages the Qwen2-1.5B-Instruct model from Hugging Face, offering a powerful tool for creating conversational AI applications.
